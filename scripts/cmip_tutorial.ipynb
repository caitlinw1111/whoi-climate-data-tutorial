{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d97c2fd-c240-42a5-a4fa-08a97dea755f",
   "metadata": {},
   "source": [
    "# Overview\n",
    "__In this notebook, we'll:__\n",
    "1. Look at examples of commonly-used xarray operations (e.g. loading and plotting data, preprocessing)\n",
    "2. Look at an example of how to apply concepts from lecture to output from a \"stochastic climate model\"\n",
    "3. Apply concepts from lecture to output from CMIP data\n",
    "\n",
    "__\"Practical\" learning objectives:__\n",
    "- Become familiar with basics of manipulating gridded climate data\n",
    "\n",
    "__Conceptual learning objectives:__\n",
    "- Understand purpose of model validation\n",
    "- Understand difference between externally-forced and internal climate variability.\n",
    "- Understand why we need ensembles of climate simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94bf4ba-8446-44b2-8b40-6e6335fe980d",
   "metadata": {},
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac98056-b074-477e-baa1-8b7b3570eec5",
   "metadata": {},
   "source": [
    "#### specify path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43eb45a7-0022-4ff5-8709-8d132930700f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filepath for the mount\n",
    "cmip6_fp = \"/Volumes/cmip6/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2aa548-d668-4e5c-8507-c31a97ce59ff",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6f094-7e73-40df-832b-036df573b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "from matplotlib.dates import DateFormatter\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import cftime\n",
    "import src.utils\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "## set plotting style\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## initialize random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f9041-25ac-4899-a73e-70e88f9c50ff",
   "metadata": {},
   "source": [
    "# 1. Commonly-used operations...\n",
    "...and examples using ```xarray``` & ```matplotlib```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa46685c-06b0-4da5-8632-b611000f34f6",
   "metadata": {},
   "source": [
    "### Opening data\n",
    "We're going to work with a \"reanalysis\" product located on the CMIP6 archive. As a reminder from lecture, a reanalysis is a hybrid of model output and observations. Observations (e.g., of rainfall, temperature, or ocean salinity) are sparse (& irregular) in time in space. The purpose of the reanalysis is to fill in the gaps, creating a nice \"gridded\" dataset which *is* regular in time and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10af6e4-e181-4b53-aaa8-782f61e893d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify file path to ERA5 reanalysis product.\n",
    "## We'll look at surface temperature\n",
    "era5_path = f\"{cmip6_fp}/era5/reanalysis/single-levels/monthly-means/2m_temperature\"\n",
    "\n",
    "## List the first few files in the folder:\n",
    "file_list = glob.glob(f\"{era5_path}/*.nc\")\n",
    "print(np.sort(file_list)[:4])\n",
    "\n",
    "## Load a single file using xarray\n",
    "T2m_1980 = xr.open_dataset(f\"{era5_path}/1980_2m_temperature.nc\")\n",
    "T2m_1980.load()\n",
    "# loads into memory\n",
    "\n",
    "## open the first 3 files (but don't load to memory)\n",
    "T2m = xr.open_mfdataset(file_list[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098ec0c8-1583-4843-bb42-45197336dbc5",
   "metadata": {},
   "source": [
    "To subset data, use the ```.isel``` / ```.sel``` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a6a227-0898-4bec-a6ad-9efe368e15c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select data for Jan 1., two different ways\n",
    "print(\n",
    "    np.allclose(\n",
    "        T2m_1980[\"t2m\"].isel(time=0).values,\n",
    "        T2m_1980[\"t2m\"].sel(time=\"1980-01-01\").values,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "## function to subset longitude/latitude\n",
    "def trim_to_north_atl(x):\n",
    "    \"\"\"trims data to the North Pacific region\"\"\"\n",
    "\n",
    "    ## lon/lat boundaries for N. Pacific\n",
    "    lon_range = [260, 360]\n",
    "    lat_range = [70, 3]\n",
    "\n",
    "    ## trim the data\n",
    "    x_trimmed = x.sel(longitude=slice(*lon_range), latitude=slice(*lat_range))\n",
    "\n",
    "    return x_trimmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aeeda12-b0ac-4a99-bf1d-e72a4b662b17",
   "metadata": {},
   "source": [
    "If we only care about a subset of the data (i.e., not the whole globe), it can be helpful to subset it *while* loading. To do this, pass a subsetting function to ```xr.open_mfdataset```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9734dbb1-f0f0-4027-ad2b-743a95f2af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load trimmed data\n",
    "T2m_trimmed = xr.open_mfdataset(file_list[:3], preprocess=trim_to_north_atl)\n",
    "\n",
    "## Compare size to original data\n",
    "print(f\"Shape of raw data:     {T2m['t2m'].shape}\")\n",
    "print(f\"Shape of trimmed data: {T2m_trimmed['t2m'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596c4971-8666-4a7e-b8cd-5f4bc536a507",
   "metadata": {},
   "source": [
    "### plotting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f842b0e9-95cd-4db7-b783-3a5db881401f",
   "metadata": {},
   "source": [
    "First, let's define a function which draws a blank map (don't worry about the details for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcbef75-143b-4cd1-8b89-b1d76dcf4e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, a generic plot setup function\n",
    "def plot_setup(ax, lon_range, lat_range, xticks, yticks, scale):\n",
    "    \"\"\"\n",
    "    Create map background for plotting spatial data.\n",
    "    Arguments:\n",
    "        - ax: Matplotlib object containing everything in the plot.\n",
    "            (I think of it as the plot \"canvas\")\n",
    "        - lon_range/lat_range: 2-element arrays, representing plot boundaries\n",
    "        - xticks/yticks: location for lon/lat labels\n",
    "        - scale: number which controls linewidth and fontsize\n",
    "\n",
    "    Returns a modified 'ax' object.\n",
    "    \"\"\"\n",
    "\n",
    "    ## specify transparency/linewidths\n",
    "    grid_alpha = 0.1 * scale\n",
    "    grid_linewidth = 0.5 * scale\n",
    "    coastline_linewidth = 0.3 * scale\n",
    "    label_size = 8 * scale\n",
    "\n",
    "    ## crop map and plot coastlines\n",
    "    ax.set_extent([*lon_range, *lat_range], crs=ccrs.PlateCarree())\n",
    "    ax.coastlines(linewidth=coastline_linewidth)\n",
    "\n",
    "    ## plot grid\n",
    "    gl = ax.gridlines(\n",
    "        draw_labels=True,\n",
    "        linestyle=\"--\",\n",
    "        alpha=grid_alpha,\n",
    "        linewidth=grid_linewidth,\n",
    "        color=\"k\",\n",
    "        zorder=1.05,\n",
    "    )\n",
    "\n",
    "    ## add tick labels\n",
    "    gl.bottom_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {\"size\": label_size}\n",
    "    gl.ylabel_style = {\"size\": label_size}\n",
    "    gl.ylocator = mticker.FixedLocator(yticks)\n",
    "    gl.xlocator = mticker.FixedLocator(xticks)\n",
    "\n",
    "    return ax, gl\n",
    "\n",
    "\n",
    "## Next, a function to plot the North Atlantic\n",
    "def plot_setup_north_atl(ax, scale=1):\n",
    "    \"\"\"Create map background for plotting spatial data.\n",
    "    Returns modified 'ax' object.\"\"\"\n",
    "\n",
    "    ## specify range and ticklabels for plot\n",
    "    lon_range = [-100, 10]\n",
    "    lat_range = [3, 70]\n",
    "    xticks = [-80, -60, -40, -20, 0]\n",
    "    yticks = [20, 40, 60]\n",
    "\n",
    "    ax, gl = plot_setup(ax, lon_range, lat_range, xticks, yticks, scale)\n",
    "\n",
    "    return ax, gl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc138a-2e6e-4d88-bd10-5c27c0948946",
   "metadata": {},
   "source": [
    "Next, create a blank canvas and modify it using our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc7357b-e030-41c3-9998-39819827ad78",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a figure object (can contain multiple \"Axes\" object)\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "\n",
    "## add Axes object (blank canvas for our plot)\n",
    "ax = fig.add_subplot(projection=ccrs.PlateCarree())\n",
    "ax, gl = plot_setup_north_atl(ax)\n",
    "\n",
    "## Let's plot T2m data for Jan 1, 1980\n",
    "t2m_plot = ax.contourf(\n",
    "    T2m_1980.longitude,\n",
    "    T2m_1980.latitude,\n",
    "    T2m_1980[\"t2m\"].isel(time=0),\n",
    "    levels=np.arange(260, 304, 4),  # contour levels to plot\n",
    "    cmap=\"cmo.thermal\",  # colormap (see https://matplotlib.org/cmocean/)\n",
    "    extend=\"both\",  # includes values outside of contour bounds\n",
    ")\n",
    "\n",
    "## add a colorbar\n",
    "cb = fig.colorbar(t2m_plot, orientation=\"vertical\", label=r\"$K$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0887b4ca-fdb6-447d-ad08-6fbf224fbf7e",
   "metadata": {},
   "source": [
    "### grid-wise and grid-to-point correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64620ca0-27d7-41ba-be38-7bc6a0e62678",
   "metadata": {},
   "source": [
    "### spatial average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ca2b89-eb50-4868-925e-b53e3adbbfcb",
   "metadata": {},
   "source": [
    "### remove seasonal cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f10ac2-6978-43b6-b1d2-9f753a918d68",
   "metadata": {},
   "source": [
    "### detrending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbe7c83-4982-425e-a9ef-fc468492c5db",
   "metadata": {},
   "source": [
    "### interpolation / resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da01078-2a64-4042-9def-ccc97092c352",
   "metadata": {},
   "source": [
    "### Regridding data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ee643-bc9b-4492-91af-c733170d9829",
   "metadata": {},
   "source": [
    "# Example: analysis of synthetic climate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c726f-c8a5-4b3f-b38f-6c96f0b68839",
   "metadata": {},
   "source": [
    "#### Simulate synthetic climate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6885f12-a1fa-4597-bca8-9eeb8729c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify number of ensemble members and end year for simulation\n",
    "n_members = 1000\n",
    "tf = 2006\n",
    "\n",
    "## simulation pre-industrial and warming scenarios\n",
    "T_PI = src.utils.markov_simulation(ti=1850, tf=tf, n_members=n_members, trend=0)\n",
    "T_warming = src.utils.markov_simulation(\n",
    "    ti=1850, tf=tf, n_members=n_members, trend=0.005\n",
    ")\n",
    "\n",
    "## for convenience, get subset of pre-industrial control which overlaps with warming\n",
    "T_PI_hist = T_PI.sel(year=T_warming.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e911ee-1cf4-4249-8f11-26e274c0629a",
   "metadata": {},
   "source": [
    "#### Plot a random sample from each simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb21e67f-dcf4-483b-913d-5ad4535d30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a random sample\n",
    "idx = rng.choice(T_PI.ensemble_member)\n",
    "\n",
    "# make the plot\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "ax.plot(\n",
    "    T_PI_hist.year,\n",
    "    T_PI_hist.sel(ensemble_member=idx),\n",
    "    color=\"black\",\n",
    "    label=\"P.I. control\",\n",
    ")\n",
    "ax.plot(\n",
    "    T_warming.year, T_warming.sel(ensemble_member=idx), color=\"red\", label=\"warming\"\n",
    ")\n",
    "\n",
    "## label axes\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(r\"SST anomaly ($^{\\circ}C$)\")\n",
    "ax.legend(prop={\"size\": 10})\n",
    "ax.set_title(\"random ensemble member\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0bc731-d9cd-48e6-b8a9-5c6b1ed0c771",
   "metadata": {},
   "source": [
    "#### Plot ensemble mean and spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f225213f-3d63-49ba-92e9-34b99ced5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ensemble_spread(ax, T, color, label=None):\n",
    "    \"\"\"plot mean and +/- 1 standard dev. of ensemble on\n",
    "    given ax object.\"\"\"\n",
    "\n",
    "    ## compute stats\n",
    "    mean = T.mean(\"ensemble_member\")\n",
    "    std = T.std(\"ensemble_member\")\n",
    "\n",
    "    ## plot mean\n",
    "    mean_plot = ax.plot(mean.year, mean, label=label, color=color)\n",
    "\n",
    "    ## plot spread\n",
    "    ax.plot(mean.year, mean + std, lw=0.5, c=mean_plot[0].get_color())\n",
    "    ax.plot(mean.year, mean - std, lw=0.5, c=mean_plot[0].get_color())\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "## Plot ensemble stats\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "## plot data\n",
    "plot_ensemble_spread(ax, T_PI_hist, color=\"black\", label=\"P.I. control\")\n",
    "plot_ensemble_spread(ax, T_warming, color=\"red\", label=\"warming\")\n",
    "\n",
    "## label axes\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(r\"SST anomaly ($^{\\circ}C$)\")\n",
    "ax.legend(prop={\"size\": 10})\n",
    "ax.set_title(\"Ensemble results\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a597d-76be-43bf-a704-f733f5e593af",
   "metadata": {},
   "source": [
    "#### Is the trend significant?\n",
    "- histogram for PI control (generate by computing trend for 1,000 random 40-year segments)\n",
    "- compare to trend in warming simulation over last 40 years and for period 1900-1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7c302-1179-4e66-90aa-c0cae6e2b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(data, dim=\"year\"):\n",
    "    \"\"\"Function to compute linear trend of SST,\n",
    "    in deg/century.\"\"\"\n",
    "\n",
    "    ## fit linear trend to data\n",
    "    coefs = data.polyfit(dim=dim, deg=1)[\"polyfit_coefficients\"]\n",
    "\n",
    "    ## Get slope (degree=1; intercept is given by degree=0).\n",
    "    ## Note: units are in deg/year\n",
    "    slope = coefs.sel(degree=1)\n",
    "\n",
    "    ## convert units to deg/century\n",
    "    slope *= 100\n",
    "\n",
    "    return slope\n",
    "\n",
    "\n",
    "def plot_histogram_comparison(ax, samples0, samples1, label0=None, label1=None):\n",
    "    \"\"\"\n",
    "    Compute two histograms, one each for samples0 and samples1.\n",
    "    Plot the results on the specified ax object, and label histograms\n",
    "    'label0' and 'label1', respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    ## First, make the histograms.\n",
    "    # specify histogram bins\n",
    "    bin_width = 0.5\n",
    "    bin_edges = np.arange(-4.75, 4.75 + bin_width, bin_width)\n",
    "\n",
    "    # compute histograms\n",
    "    hist0, _ = np.histogram(samples0, bins=bin_edges)\n",
    "    hist1, _ = np.histogram(samples1, bins=bin_edges)\n",
    "\n",
    "    ## plot histograms\n",
    "    ax.stairs(values=hist0, edges=bin_edges, color=\"k\", label=label0)\n",
    "    ax.stairs(\n",
    "        values=hist1,\n",
    "        edges=bin_edges,\n",
    "        color=\"r\",\n",
    "        label=label1,\n",
    "        fill=True,\n",
    "        alpha=0.3,\n",
    "    )\n",
    "\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_xlabel(r\"Warming trend ($^{\\circ}C~/~$century)\")\n",
    "\n",
    "    ## label plot\n",
    "    ax.set_ylabel(\"Count\")\n",
    "    ax.set_xlabel(r\"Warming trend ($^{\\circ}C~/~$century)\")\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_histogram_comparison_wrapper(ax, years):\n",
    "    \"\"\"wrapper function to plot histogram comparison for given subset of years\"\"\"\n",
    "\n",
    "    ## Get trends for each ensemble members\n",
    "    T_PI_subset = T_PI.sel(year=years)\n",
    "    T_warming_subset = T_warming.sel(year=years)\n",
    "    trends_PI = get_slope(T_PI_subset)\n",
    "    trends_warming = get_slope(T_warming_subset)\n",
    "\n",
    "    ## make the plot\n",
    "    ax = plot_histogram_comparison(\n",
    "        ax,\n",
    "        samples0=trends_PI,\n",
    "        samples1=trends_warming,\n",
    "        label0=\"PI control\",\n",
    "        label1=\"warming\",\n",
    "    )\n",
    "\n",
    "    ## plot ensemble means\n",
    "    T_PI_mean = T_PI_subset.mean(\"ensemble_member\")\n",
    "    T_warming_mean = T_warming_subset.mean(\"ensemble_member\")\n",
    "    ax.axvline(get_slope(T_PI_mean), ls=\"--\", c=\"k\", lw=1)\n",
    "    ax.axvline(get_slope(T_warming_mean), ls=\"--\", c=\"r\", lw=1)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647d3f3-a9bc-4020-b421-80ee7543cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "## Plot data for each subset of years\n",
    "axs[0] = plot_histogram_comparison_wrapper(axs[0], years=np.arange(1850, 1890))\n",
    "axs[1] = plot_histogram_comparison_wrapper(axs[1], years=np.arange(1966, 2006))\n",
    "\n",
    "## label plot\n",
    "axs[0].set_title(\"First 40 years\")\n",
    "axs[1].set_title(\"Last 40 years\")\n",
    "axs[0].legend(prop={\"size\": 10})\n",
    "axs[1].set_yticks([])\n",
    "axs[1].set_ylabel(None)\n",
    "axs[1].set_ylim(axs[0].get_ylim())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cac783-159f-4169-8768-a222707f4ee1",
   "metadata": {},
   "source": [
    "# Now it's your turn...\n",
    "Start by picking a variable/index to analyze (e.g., SST at a specific location or averaged over a specified region), a reanalysis product from the CMIP archive, and a model from the CMIP archive.\n",
    "\n",
    "#### Model validation\n",
    "1. Load the data and make a plot.\n",
    "2. Compute the index for both the reanalysis and the model (in the historical simulation).\n",
    "3. How do the statistics compare over the overlapping period? (e.g., mean, standard deviation, seasonal cycle, power spectrum).\n",
    "\n",
    "#### Is there evidence of a climate change signal?\n",
    "1. Next, compute the index in the model's pre-industrial control simulation (__should this be a last millenium simulation?).\n",
    "2. Create a histogram of trends in the control simulation by computing the trends of randomly-sampled 40-year segments.\n",
    "3. Based on this histogram, is the model-simulated trend (from the last 40 years, in the historical simulation) significant?\n",
    "   \n",
    "#### What are the projected future changes?\n",
    "1. Next, compute the index in a future warming scenario (using the same model).\n",
    "2. How do the statistics/histogram shift in the future warming scenario?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
