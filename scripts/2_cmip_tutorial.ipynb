{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "beec07dc-7082-4403-9982-a0bfa8316428",
   "metadata": {},
   "source": [
    "# Overview: identifying a climate change \"signal\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4abcfa-f7f3-430f-830f-1f254eeee2c4",
   "metadata": {},
   "source": [
    "#### Motivation\n",
    "The purpose of this tutorial is to demonstrate how models are used to assess climate change, or literally, a \"change in climate\". Why do we need models? One reason is that changes in climate, or the \"background state\" of the system, are often smaller than the internal variability of the system, meaning we need lots of samples – more than we have from observations – to estimate it accurately. \n",
    "\n",
    "As a concrete example, imagine the daily weather in Woods Hole is sampled from a probability distribution (e.g., 30% chance of rain, 70% chance of sun). Then the mean of this distribution (averaged over 30 years, for example) is the climate in Woods Hole, and the spread in this distribution (quantified by the standard deviation, for example) reflects natural variability. Climate *change*, in this example, corresponds to a shift in the mean of the probability distribution. Detecting a shift in the mean is harder if (i) the spread in the distribution is large compared to the shift or (ii) if we have a limited number of samples.  \n",
    "\n",
    "Simulations from models increase the number of samples we can use to estimate the mean (and changes to the mean over time). Models also allow us to conduct \"controlled\" experiments, where, for example, we compare simulations with and without greenhouse gas emissions. In this context, the simulation without greenhouse gas emissions is the \"control\", which we're using as a baseline for comparison to the simulation *with* greenhouse gas emissions (the \"experimental\" simulation). One commonly used baseline is the \"pre-industrial control\", in which emission levels are fixed to pre-industrial levels and the model is run for a long time ($\\sim1,000$ years).\n",
    "\n",
    "#### Outline for this tutorial\n",
    "\n",
    "To demonstrate these concepts, we'll look at a synthetic example, using a stochastic \"climate model\", where we know the \"true\" level of warming. We'll look at two ways of estimating climate and changes to it:\n",
    "1. averaging over a large ensemble of \"short\" simulations\n",
    "2. randomly sampling from a long pre-industrial control simulation\n",
    "\n",
    "First, we'll simulate an artificial climate under two scenarios: a pre-industrial scenario and a warming scenario. For each scenario, we'll run lots of simulations, generating an ensemble. Averaging over the ensemble members at each time gives us an estimate of the mean state (the climate) and the natural variability in the system. Comparing the ensemble mean between the control and warming scenarios gives us an estimate of how much the climate has changed. \n",
    "\n",
    "Next, we'll estimate the control climate using a single (longer) pre-industrial control simulation. Because the climate in the control simulation is – by construction – not changing, we can estimate the climate by averaging over time, rather than over ensemble members. We'll show that the estimate for the pre-industrial climate using this approach is similar to that obtained from the ensemble approach.\n",
    "\n",
    "Finally, you'll assess climate change for your own problem using the pre-industrial control."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2aa548-d668-4e5c-8507-c31a97ce59ff",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f6f094-7e73-40df-832b-036df573b202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "from matplotlib.dates import DateFormatter\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import cftime\n",
    "import src.utils\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.dates as mdates\n",
    "import xesmf as xe\n",
    "\n",
    "## set plotting style\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## initialize random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c93521-00d1-4452-8205-d20c009b282c",
   "metadata": {},
   "source": [
    "## Large ensemble approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "537c726f-c8a5-4b3f-b38f-6c96f0b68839",
   "metadata": {},
   "source": [
    "### Run stochastic climate model\n",
    "First, we'll run the model under two scenarios: pre-industrial (\"PI\") control and warming. Below, specify the magnitude of the warming trend and the number of ensemble members for each scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6885f12-a1fa-4597-bca8-9eeb8729c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "## specify number of ensemble members and end year for simulation\n",
    "warming_trend = 0.005  # warming trend, in deg C / year\n",
    "n_members = 1000  # number of ensemble members\n",
    "\n",
    "## simulation pre-industrial and warming scenarios\n",
    "T_PI = src.utils.markov_simulation(\n",
    "    ti=1850, tf=2006, n_members=n_members, trend=0, nyears_spinup=5\n",
    ")\n",
    "T_warming = src.utils.markov_simulation(\n",
    "    ti=1850, tf=2006, n_members=n_members, trend=warming_trend, nyears_spinup=5\n",
    ")\n",
    "\n",
    "## for convenience, get subset of pre-industrial control which overlaps with warming\n",
    "T_PI_hist = T_PI.sel(year=T_warming.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e911ee-1cf4-4249-8f11-26e274c0629a",
   "metadata": {},
   "source": [
    "### Plot output from each scenario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182d77fb-afa7-49b8-ac0a-940043f143fd",
   "metadata": {},
   "source": [
    "First, look at a single ensemble member from each scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb21e67f-dcf4-483b-913d-5ad4535d30f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose a random sample\n",
    "idx = rng.choice(T_PI.ensemble_member)\n",
    "\n",
    "# make the plot\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "ax.plot(\n",
    "    T_PI_hist.year,\n",
    "    T_PI_hist.sel(ensemble_member=idx),\n",
    "    color=\"black\",\n",
    "    label=\"P.I. control\",\n",
    ")\n",
    "ax.plot(\n",
    "    T_warming.year, T_warming.sel(ensemble_member=idx), color=\"red\", label=\"warming\"\n",
    ")\n",
    "\n",
    "## label axes\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(r\"SST anomaly ($^{\\circ}C$)\")\n",
    "ax.legend(prop={\"size\": 10})\n",
    "ax.set_title(\"random ensemble member\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0bc731-d9cd-48e6-b8a9-5c6b1ed0c771",
   "metadata": {},
   "source": [
    "Next, let's look at the ensemble mean and spread. To quantify the spread, we'll compute the standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f225213f-3d63-49ba-92e9-34b99ced5560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ensemble_spread(ax, T, color, label=None):\n",
    "    \"\"\"plot mean and +/- 1 standard dev. of ensemble on\n",
    "    given ax object.\"\"\"\n",
    "\n",
    "    ## compute stats\n",
    "    mean = T.mean(\"ensemble_member\")\n",
    "    std = T.std(\"ensemble_member\")\n",
    "\n",
    "    ## plot mean\n",
    "    mean_plot = ax.plot(mean.year, mean, label=label, color=color)\n",
    "\n",
    "    ## plot spread\n",
    "    ax.plot(mean.year, mean + std, lw=0.5, c=mean_plot[0].get_color())\n",
    "    ax.plot(mean.year, mean - std, lw=0.5, c=mean_plot[0].get_color())\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "## Plot ensemble stats\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "## plot data\n",
    "plot_ensemble_spread(ax, T_PI_hist, color=\"black\", label=\"P.I. control\")\n",
    "plot_ensemble_spread(ax, T_warming, color=\"red\", label=\"warming\")\n",
    "\n",
    "## label axes\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(r\"SST anomaly ($^{\\circ}C$)\")\n",
    "ax.legend(prop={\"size\": 10})\n",
    "ax.set_title(r\"Ensemble mean $\\pm$1 standard dev.\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c272256-3f1e-4338-b047-6475a74cc46f",
   "metadata": {},
   "source": [
    "### Assessing climate change"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965a597d-76be-43bf-a704-f733f5e593af",
   "metadata": {},
   "source": [
    "Next, we'll return to the probabilistic view of climate and weather. One straightforward approach would be to compute SST histograms for each scenario at the end of the simulation, and compare them (one could ask \"are the means of these distributions significantly different?\"). We'll ask a slightly more involved question: is the linear trend in SST over the last 40 years statistically significant?\n",
    "\n",
    "To do this, we'll compute the linear trend in each ensemble member, then create a histogram of trends for each scenario. Finally, we'll compare the histograms for PI control and warming scenarios.\n",
    "\n",
    "Below, we write functions to compute the linear trend (```get_slope```), to estimate the probability distribution function (```get_pdf```), and to plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce7c302-1179-4e66-90aa-c0cae6e2b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_slope(data, dim=\"year\"):\n",
    "    \"\"\"Function to compute linear trend of SST,\n",
    "    in deg/century.\"\"\"\n",
    "\n",
    "    ## fit linear trend to data\n",
    "    coefs = data.polyfit(dim=dim, deg=1)[\"polyfit_coefficients\"]\n",
    "\n",
    "    ## Get slope (degree=1; intercept is given by degree=0).\n",
    "    ## Note: units are in deg/year\n",
    "    slope = coefs.sel(degree=1)\n",
    "\n",
    "    ## convert units to deg/century\n",
    "    slope *= 100\n",
    "\n",
    "    return slope\n",
    "\n",
    "\n",
    "def get_pdf(samples):\n",
    "    \"\"\"function to get probability distribution function from samples\"\"\"\n",
    "\n",
    "    ## First, make a histogram.\n",
    "\n",
    "    # specify bin edges for histogram\n",
    "    bin_width = 0.5\n",
    "    bin_edges = np.arange(-4.75, 4.75 + bin_width, bin_width)\n",
    "\n",
    "    # compute histogram\n",
    "    hist, _ = np.histogram(samples, bins=bin_edges)\n",
    "\n",
    "    ## normalize, to form PDF\n",
    "    norm_factor = (bin_width * hist).sum()\n",
    "    pdf = hist / norm_factor\n",
    "\n",
    "    return pdf, bin_edges\n",
    "\n",
    "\n",
    "def plot_pdf_comparison(ax, samples0, samples1, label0=None, label1=None, color1=\"r\"):\n",
    "    \"\"\"\n",
    "    Plot comparison of 2 PDFs on the specified ax object, and label them\n",
    "    'label0' and 'label1', respectively. 'color1' is the color for PDF calculated\n",
    "    from 'samples1' (only the outline of pdf for 'samples1' is plotted).\n",
    "    \"\"\"\n",
    "\n",
    "    ## calculate PDFs\n",
    "    pdf0, bin_edges = get_pdf(samples0)\n",
    "    pdf1, _ = get_pdf(samples1)\n",
    "\n",
    "    ## plot histograms\n",
    "    ax.stairs(values=pdf0, edges=bin_edges, color=\"k\", label=label0)\n",
    "    ax.stairs(\n",
    "        values=pdf1,\n",
    "        edges=bin_edges,\n",
    "        color=color1,\n",
    "        label=label1,\n",
    "        fill=True,\n",
    "        alpha=0.3,\n",
    "    )\n",
    "\n",
    "    ## label plot\n",
    "    ax.set_ylabel(\"Prob.\")\n",
    "    ax.set_xlabel(r\"Warming trend ($^{\\circ}C~/~$century)\")\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "def plot_pdf_comparison_wrapper0(ax, years):\n",
    "    \"\"\"wrapper function to plot histogram comparison for given subset of years\"\"\"\n",
    "\n",
    "    ## Get trends for each ensemble member\n",
    "    trends_PI = get_slope(T_PI.sel(year=years))\n",
    "    trends_warming = get_slope(T_warming.sel(year=years))\n",
    "\n",
    "    ## make the plot\n",
    "    ax = plot_pdf_comparison(\n",
    "        ax,\n",
    "        samples0=trends_PI,\n",
    "        samples1=trends_warming,\n",
    "        label0=\"PI control\",\n",
    "        label1=\"warming\",\n",
    "    )\n",
    "\n",
    "    ## plot ensemble means\n",
    "    ax.axvline(trends_PI.mean(), ls=\"--\", c=\"k\", lw=1)\n",
    "    ax.axvline(trends_warming.mean(), ls=\"--\", c=\"r\", lw=1)\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f35c3c-cb5b-4162-9c2e-797fd468ff55",
   "metadata": {},
   "source": [
    "Next, we apply these functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c647d3f3-a9bc-4020-b421-80ee7543cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get years to compare\n",
    "nyears = 40\n",
    "early_years = T_warming.year.values[:nyears]\n",
    "late_years = T_warming.year.values[-nyears:]\n",
    "\n",
    "## Make plot\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "## Plot data for each subset of years\n",
    "axs[0] = plot_pdf_comparison_wrapper0(axs[0], years=early_years)\n",
    "axs[1] = plot_pdf_comparison_wrapper0(axs[1], years=late_years)\n",
    "\n",
    "## label plot\n",
    "axs[0].set_title(f\"First {nyears} years\")\n",
    "axs[1].set_title(f\"Last {nyears} years\")\n",
    "axs[0].legend(prop={\"size\": 10})\n",
    "axs[1].set_yticks([])\n",
    "axs[1].set_ylabel(None)\n",
    "axs[1].set_ylim(axs[0].get_ylim())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543f66e6-412e-4074-883b-494158e7a8c8",
   "metadata": {},
   "source": [
    "## Random sampling approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abdf86c-2408-45d9-9a45-7f05d283ec9c",
   "metadata": {},
   "source": [
    "Next, we'll do the same exercise but will estimate the PDF/histogram for the pre-industrial control in a different way: using a single, long simulation. Whereas before we used a large ensemble of pre-industrial simulations (each spanning the period 1850-2006), here we'll use a single, 1,000-year long simulation. To compute the histogram, we'll select random (overlapping) 40-year samples from the simulation, rather than averaging over ensemble members. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77be4f24-5882-4d1e-b490-4797a489e8b5",
   "metadata": {},
   "source": [
    "First, run the long simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8972e88-e964-4ed5-9a3f-a4429be248e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 1,000 year simulation\n",
    "T_PI_long = src.utils.markov_simulation(\n",
    "    ti=1000, tf=2000, n_members=1, trend=0, nyears_spinup=5\n",
    ")\n",
    "\n",
    "## get rid of ensemble dimension\n",
    "T_PI_long = T_PI_long.isel(ensemble_member=0, drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a2611e-d265-4169-b399-9f3baa3e392c",
   "metadata": {},
   "source": [
    "Next, some functions to select random samples from the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec64451-f8b1-459a-a4db-1a45334bf3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_sample(nyears):\n",
    "    \"\"\"function draws a random sample from T_PI_long,\n",
    "    and computes trend. 'nyears' is length of sample\"\"\"\n",
    "\n",
    "    ## get start year for trend\n",
    "    max_idx = len(T_PI_long.year) - nyears\n",
    "    idx_start = rng.choice(np.arange(0, max_idx))\n",
    "\n",
    "    ## get data subset\n",
    "    T_PI_sample = T_PI_long.isel(year=slice(idx_start, idx_start + nyears))\n",
    "\n",
    "    ## compute trend for sample\n",
    "    return get_slope(T_PI_sample)\n",
    "\n",
    "\n",
    "def get_random_samples(nsamples, nyears):\n",
    "    \"\"\"get multiple random samples\"\"\"\n",
    "\n",
    "    ## get random samples\n",
    "    samples = [get_random_sample(nyears) for _ in tqdm(np.arange(nsamples))]\n",
    "\n",
    "    ## Put in xr.DataArray.\n",
    "    sample_dim = pd.Index(np.arange(nsamples), name=\"sample\")\n",
    "    samples = xr.concat(samples, dim=sample_dim)\n",
    "    return samples\n",
    "\n",
    "\n",
    "## get random samples\n",
    "samples = get_random_samples(nsamples=len(T_PI.ensemble_member), nyears=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc09abc3-9eed-4727-9169-0e3910715015",
   "metadata": {},
   "source": [
    "Finally, compare the histogram estimated using the ensemble mean approach to the histogram estimated using the random sampling (or \"Monte-Carlo\") approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d8ff8d-c51d-4242-a5f0-3695ef72c0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(4, 3))\n",
    "ax = fig.add_subplot()\n",
    "\n",
    "ax = plot_pdf_comparison(\n",
    "    ax,\n",
    "    samples0=get_slope(T_PI.sel(year=early_years)),\n",
    "    samples1=samples,\n",
    "    label0=\"Ensemble mean\",\n",
    "    label1=\"Monte-Carlo\",\n",
    "    color1=\"k\",\n",
    ")\n",
    "\n",
    "ax.legend(prop={\"size\": 8})\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cac783-159f-4169-8768-a222707f4ee1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Now it's your turn...\n",
    "Start by picking a variable/index to analyze (e.g., SST at a specific location or averaged over a specified region), a reanalysis product from the CMIP archive, and a model from the CMIP archive.\n",
    "\n",
    "#### Model validation\n",
    "1. Load the data and make a plot.\n",
    "2. Compute the index for both the reanalysis and the model (in the historical simulation).\n",
    "3. How do the statistics compare over the overlapping period? (e.g., mean, standard deviation, seasonal cycle, power spectrum).\n",
    "\n",
    "#### Is there evidence of a climate change signal?\n",
    "1. Next, compute the index in the model's pre-industrial control simulation (__should this be a last millenium simulation?).\n",
    "2. Create a histogram of trends in the control simulation by computing the trends of randomly-sampled 40-year segments.\n",
    "3. Based on this histogram, is the model-simulated trend (from the last 40 years, in the historical simulation) significant?\n",
    "   \n",
    "#### What are the projected future changes?\n",
    "1. Next, compute the index in a future warming scenario (using the same model).\n",
    "2. How do the statistics/histogram shift in the future warming scenario?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
