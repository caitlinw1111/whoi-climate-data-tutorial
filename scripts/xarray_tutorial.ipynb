{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55806674-6c8c-4f21-b172-0c0b187e6687",
   "metadata": {},
   "source": [
    "# Overview\n",
    "__In this notebook, we'll:__\n",
    "1. Look at examples of commonly-used xarray operations (e.g. loading and plotting data, preprocessing)\n",
    "2. Look at an example of how to apply concepts from lecture to output from a \"stochastic climate model\"\n",
    "3. Apply concepts from lecture to output from CMIP data\n",
    "\n",
    "__\"Practical\" learning objectives:__\n",
    "- Become familiar with basics of manipulating gridded climate data\n",
    "\n",
    "__Conceptual learning objectives:__\n",
    "- Understand purpose of model validation\n",
    "- Understand difference between externally-forced and internal climate variability.\n",
    "- Understand why we need ensembles of climate simulations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094c8d4e-1130-425a-ad9b-b12649f144a0",
   "metadata": {},
   "source": [
    "# 0. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f72e578-0c5e-4241-8a00-c2ea623b597d",
   "metadata": {},
   "source": [
    "#### specify path to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cc9fa3-f8c9-462d-9c6a-ebacbbe646c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## filepath for the mount\n",
    "cmip6_fp = \"/Volumes/cmip6/data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c416fa-d265-4595-83a3-95bd470ad5fc",
   "metadata": {},
   "source": [
    "#### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f319a253-bef7-456e-b46b-f824a0c74014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "from matplotlib.dates import DateFormatter\n",
    "import seaborn as sns\n",
    "import glob\n",
    "import cftime\n",
    "import src.utils\n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.ticker as mticker\n",
    "import matplotlib.dates as mdates\n",
    "import xesmf as xe\n",
    "\n",
    "## set plotting style\n",
    "sns.set(rc={\"axes.facecolor\": \"white\", \"axes.grid\": False})\n",
    "\n",
    "## initialize random number generator\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4379e1-30ae-464b-8376-b28117aa705b",
   "metadata": {},
   "source": [
    "# 1. Commonly-used operations...\n",
    "...and examples using ```xarray``` & ```matplotlib```.  \n",
    "\n",
    "[Xarray](https://xarray.dev/) is a Python package useful for working with gridded climate data and netcdf files. I think of it as a high-level \"wrapper\" for lower-level packages like ```numpy``` and ```pandas```. While the core of a ```xarray.DataArray``` object is a ```numpy.array```, the ```xarray``` object includes dimension names and additional metadata. This tends to make code easier to interpret: for example, to average over latitudes in a numpy array, you have to keep track of which array dimension corresponds to latitude – e.g., ```data.mean(axis=2)```, if latitude is the 2$^{nd}$ dimension – whereas in xarray you don't: ```data.mean(dim=\"latitude\")```.  \n",
    "\n",
    "Here, we have a few examples of commonly-used patterns/operations when working with data on WHOI's servers; there is a [more complete tutorial on the ```xarray``` website](https://tutorial.xarray.dev/overview/xarray-in-45-min.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866f248b-4640-4e33-9e1a-0cb594181ec8",
   "metadata": {},
   "source": [
    "## Opening data\n",
    "We're going to work with a \"reanalysis\" product located on the CMIP6 archive. As a reminder from lecture, a reanalysis is a hybrid of model output and observations. Observations (e.g., of rainfall, temperature, or ocean salinity) are sparse (& irregular) in time in space. The purpose of the reanalysis is to fill in the gaps, creating a nice \"gridded\" dataset which *is* regular in time and space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aa459a-7998-4ef5-aeb5-25a74f678be3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## specify file path to ERA5 reanalysis product.\n",
    "## We'll look at surface temperature\n",
    "era5_path = f\"{cmip6_fp}/era5/reanalysis/single-levels/monthly-means/2m_temperature\"\n",
    "\n",
    "## List the first few files in the folder:\n",
    "file_list = glob.glob(f\"{era5_path}/*.nc\")\n",
    "print(np.sort(file_list)[:4])\n",
    "\n",
    "## Load a single file using xarray\n",
    "T2m_1980 = xr.open_dataset(f\"{era5_path}/1980_2m_temperature.nc\")\n",
    "T2m_1980.load()\n",
    "# loads into memory\n",
    "\n",
    "## open the first 3 files (but don't load to memory)\n",
    "T2m = xr.open_mfdataset(file_list[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f74c47-df73-4ae5-bf6c-0e643e09758f",
   "metadata": {},
   "source": [
    "To subset data, use the ```.isel``` / ```.sel``` functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34adb9d-aadf-43d3-92b8-682a131db5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## select data for Jan 1., two different ways\n",
    "print(\n",
    "    np.allclose(\n",
    "        T2m_1980[\"t2m\"].isel(time=0).values,\n",
    "        T2m_1980[\"t2m\"].sel(time=\"1980-01-01\").values,\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "## function to subset longitude/latitude\n",
    "def trim_to_north_atl(x):\n",
    "    \"\"\"trims data to the North Pacific region\"\"\"\n",
    "\n",
    "    ## lon/lat boundaries for N. Pacific\n",
    "    lon_range = [260, 360]\n",
    "    lat_range = [70, 3]\n",
    "\n",
    "    ## trim the data\n",
    "    x_trimmed = x.sel(longitude=slice(*lon_range), latitude=slice(*lat_range))\n",
    "\n",
    "    return x_trimmed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105c7349-c247-44c3-a49b-711994d337dc",
   "metadata": {},
   "source": [
    "If we only care about a subset of the data (i.e., not the whole globe), it can be helpful to subset it *while* loading. To do this, pass a subsetting function to ```xr.open_mfdataset```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3728702-95d4-47ef-a0d2-e1b519428e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load trimmed data\n",
    "T2m_trimmed = xr.open_mfdataset(file_list[:3], preprocess=trim_to_north_atl).compute()\n",
    "\n",
    "## Compare size to original data\n",
    "print(f\"Shape of raw data:     {T2m['t2m'].shape}\")\n",
    "print(f\"Shape of trimmed data: {T2m_trimmed['t2m'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f7d37c-05a8-4f90-b1c3-5d3f7acb9e37",
   "metadata": {},
   "source": [
    "## plotting data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eee878-fb80-441a-b0e6-2187447d0cf4",
   "metadata": {},
   "source": [
    "First, let's define a function which draws a blank map (don't worry about the details for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bae3b0e-1dfe-4b8f-8b9d-6621eb1ae29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First, a generic plot setup function\n",
    "def plot_setup(ax, lon_range, lat_range, xticks, yticks, scale):\n",
    "    \"\"\"\n",
    "    Create map background for plotting spatial data.\n",
    "    Arguments:\n",
    "        - ax: Matplotlib object containing everything in the plot.\n",
    "            (I think of it as the plot \"canvas\")\n",
    "        - lon_range/lat_range: 2-element arrays, representing plot boundaries\n",
    "        - xticks/yticks: location for lon/lat labels\n",
    "        - scale: number which controls linewidth and fontsize\n",
    "\n",
    "    Returns a modified 'ax' object.\n",
    "    \"\"\"\n",
    "\n",
    "    ## specify transparency/linewidths\n",
    "    grid_alpha = 0.1 * scale\n",
    "    grid_linewidth = 0.5 * scale\n",
    "    coastline_linewidth = 0.3 * scale\n",
    "    label_size = 8 * scale\n",
    "\n",
    "    ## crop map and plot coastlines\n",
    "    ax.set_extent([*lon_range, *lat_range], crs=ccrs.PlateCarree())\n",
    "    ax.coastlines(linewidth=coastline_linewidth)\n",
    "\n",
    "    ## plot grid\n",
    "    gl = ax.gridlines(\n",
    "        draw_labels=True,\n",
    "        linestyle=\"--\",\n",
    "        alpha=grid_alpha,\n",
    "        linewidth=grid_linewidth,\n",
    "        color=\"k\",\n",
    "        zorder=1.05,\n",
    "    )\n",
    "\n",
    "    ## add tick labels\n",
    "    gl.bottom_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {\"size\": label_size}\n",
    "    gl.ylabel_style = {\"size\": label_size}\n",
    "    gl.ylocator = mticker.FixedLocator(yticks)\n",
    "    gl.xlocator = mticker.FixedLocator(xticks)\n",
    "\n",
    "    return ax, gl\n",
    "\n",
    "\n",
    "## Next, a function to plot the North Atlantic\n",
    "def plot_setup_north_atl(ax, scale=1):\n",
    "    \"\"\"Create map background for plotting spatial data.\n",
    "    Returns modified 'ax' object.\"\"\"\n",
    "\n",
    "    ## specify range and ticklabels for plot\n",
    "    lon_range = [-100, 0]\n",
    "    lat_range = [3, 70]\n",
    "    xticks = [-80, -60, -40, -20, 0]\n",
    "    yticks = [20, 40, 60]\n",
    "\n",
    "    ax, gl = plot_setup(ax, lon_range, lat_range, xticks, yticks, scale)\n",
    "\n",
    "    return ax, gl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35469d-c92b-46ab-bc02-4f7a8ad9bc4b",
   "metadata": {},
   "source": [
    "Next, create a blank canvas and modify it using our function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e7f373-6f9d-4f23-ae87-88175e5d02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a figure object (can contain multiple \"Axes\" object)\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "\n",
    "## add Axes object (blank canvas for our plot)\n",
    "ax = fig.add_subplot(projection=ccrs.PlateCarree())\n",
    "ax, gl = plot_setup_north_atl(ax)\n",
    "\n",
    "## Let's plot T2m data for Jan 1, 1980\n",
    "t2m_plot = ax.contourf(\n",
    "    T2m_1980.longitude,\n",
    "    T2m_1980.latitude,\n",
    "    T2m_1980[\"t2m\"].isel(time=0),\n",
    "    levels=np.arange(260, 304, 4),  # contour levels to plot\n",
    "    cmap=\"cmo.thermal\",  # colormap (see https://matplotlib.org/cmocean/)\n",
    "    extend=\"both\",  # includes values outside of contour bounds\n",
    ")\n",
    "\n",
    "## add a colorbar\n",
    "cb = fig.colorbar(t2m_plot, orientation=\"vertical\", label=r\"$K$\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2974b60-3371-4b09-bfc8-470ecbc200bf",
   "metadata": {},
   "source": [
    "## spatial average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9d528-0940-419d-9b58-a1890d6fa2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to compute cosine-weighted average over longitude and latitude\n",
    "def spatial_avg(data):\n",
    "    \"\"\"function to compute spatial average of data on grid with constant\n",
    "    longitude/latitude spacing.\"\"\"\n",
    "\n",
    "    ## first, compute cosine of latitude (after converting degrees to radians)\n",
    "    latitude_radians = np.deg2rad(T2m_trimmed.latitude)\n",
    "    cos_lat = np.cos(latitude_radians)\n",
    "\n",
    "    ## get weighted average using xarray\n",
    "    avg = data.weighted(weights=cos_lat).mean([\"longitude\", \"latitude\"])\n",
    "\n",
    "    return avg\n",
    "\n",
    "\n",
    "## \"naive\" unweighted average over longitude and latitudes\n",
    "avg_unweighted = T2m_trimmed[\"t2m\"].mean([\"latitude\", \"longitude\"])\n",
    "\n",
    "## (correct) weighted average\n",
    "avg_weighted = spatial_avg(T2m_trimmed[\"t2m\"])\n",
    "\n",
    "## compare results:\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "ax.plot(avg_unweighted.time, avg_unweighted, label=\"unweighted\")\n",
    "ax.plot(avg_weighted.time, avg_weighted, label=\"weighted\")\n",
    "\n",
    "## label plot\n",
    "ax.legend(prop={\"size\": 10})\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(r\"$K$\")\n",
    "ax.set_xticks(ax.get_xticks()[::3])\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fcb783-7fd2-4f97-b7a8-e5395c2b081a",
   "metadata": {},
   "source": [
    "### Why do we need to weight by the cosine of latitude?\n",
    "Not every element in our array represents an equal surface area of the earth: on a \"regular\" longitude-latitude grid (where the longitude and latitude spacing is constant) the area of gridcells decreases as you move away from the equator to the poles. Denoting longitude and latitude as $\\theta$ and $\\phi$, and longitude and latitude spacing as $\\delta\\theta$ and $\\delta\\phi$, the area of each gridcell is given by $\\delta A ~= R^2\\cos(\\phi)\\delta\\phi\\delta\\theta$, where $R$ is the radius of the earth. The weighted average of a variable $f$ on the sphere is then given by:\n",
    "\\begin{align}\n",
    "    \\overline{f} &= \\frac{\\sum f~\\delta A}{\\sum \\delta A} = \\frac{\\sum f~R^2\\cos\\left(\\phi\\right)~\\delta\\phi~\\delta\\theta}{\\sum R^2\\cos\\left(\\phi\\right)~\\delta\\phi~\\delta\\theta} = \\frac{R^2 ~\\delta\\phi~\\delta\\theta \\sum f~\\cos\\left(\\phi\\right)}{R^2~\\delta\\phi~\\delta\\theta \\sum \\cos(\\phi)} = \\frac{\\sum f\\cos(\\phi)}{\\sum\\cos(\\phi)},\n",
    "\\end{align}\n",
    "where we use the fact that $R^2$, $\\delta\\theta$, and $\\delta\\phi$ are constant (and can be pulled out of the summation). Therefore, to compute $\\overline{f}$, we need to compute a *weighted* average, where the weights are the cosine of the latitude."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f0a3b3-48d1-4668-9d75-77c9298f69bd",
   "metadata": {},
   "source": [
    "## identifying (and removing) the seasonal cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11f6e1f-95be-47f6-a025-49573f103a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_cyc = avg_weighted.groupby(\"time.month\").mean()\n",
    "anomalies = avg_weighted.groupby(\"time.month\") - seasonal_cyc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42586515-a795-4bef-a462-e847d2357754",
   "metadata": {},
   "source": [
    "Plot results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71289dc3-df44-46f2-9af2-32832e3491c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot seasonal cycle\n",
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "ax.plot(seasonal_cyc.month, seasonal_cyc)\n",
    "ax.set_xticks([1, 6, 11], labels=[\"Jan\", \"Jun\", \"Nov\"])\n",
    "ax.set_yticks(ticks=[285, 290, 295])\n",
    "ax.set_ylabel(r\"$K$\")\n",
    "ax.set_xlabel(\"Month\")\n",
    "ax.set_title(\"Mean seasonal cycle\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "## Plot anomalies\n",
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "\n",
    "## plot raw data\n",
    "p = ax.plot(avg_weighted.time, avg_weighted, label=\"w/ seasonal cycle\", alpha=0.5)\n",
    "ax.set_ylabel(r\"$T$ before ($K$)\", color=p[0].get_color())\n",
    "ax.set_yticks(ticks=[285, 290, 295], labels=[285, 290, 295], color=p[0].get_color())\n",
    "\n",
    "## plot after removing mean seasonal cycle\n",
    "ax_anom = ax.twinx()\n",
    "ax_anom.plot(anomalies.time, anomalies, label=\"w/o seasonal cycle\", c=\"k\")\n",
    "ax_anom.set_ylabel(r\"$T$ after ($K$)\")\n",
    "\n",
    "## Label plot\n",
    "ax.set_xticks(ax.get_xticks()[::3])\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "ax.set_title(\"Before/after removing seasonal cycle\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cbd802-9b68-4468-a9bf-267f3c060435",
   "metadata": {},
   "source": [
    "Note we can compute the seasonal cycle at every gridpoint separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1aff0-73d7-4696-ad45-1180793f3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute seasonal cycle, and plot at diff. b/n july and jan\n",
    "seasonal_cyc_spatial = T2m_trimmed[\"t2m\"].groupby(\"time.month\").mean()\n",
    "jul_jan_diff = seasonal_cyc_spatial.sel(month=7) - seasonal_cyc_spatial.sel(month=1)\n",
    "\n",
    "## Create a figure object (can contain multiple \"Axes\" object)\n",
    "fig = plt.figure(figsize=(6, 3))\n",
    "ax = fig.add_subplot(projection=ccrs.PlateCarree())\n",
    "ax, gl = plot_setup_north_atl(ax)\n",
    "\n",
    "## Plot data\n",
    "t2m_plot = ax.contourf(\n",
    "    jul_jan_diff.longitude,\n",
    "    jul_jan_diff.latitude,\n",
    "    jul_jan_diff,\n",
    "    levels=np.arange(-30, 34, 4),\n",
    "    cmap=\"cmo.balance\",\n",
    "    extend=\"both\",\n",
    ")\n",
    "\n",
    "## add a colorbar and label\n",
    "cb = fig.colorbar(\n",
    "    t2m_plot, orientation=\"vertical\", label=r\"$K$\", ticks=np.arange(-30, 45, 15)\n",
    ")\n",
    "ax.set_title(\"Jul – Jan difference\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd54c8e-fb41-40de-90ef-e1e5e1e9e321",
   "metadata": {},
   "source": [
    "Check that the order of averaging doesn't matter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74669be7-cbcc-4439-8ff9-dfba093e4b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "##  to spatial dataset\n",
    "print(np.allclose(spatial_avg(seasonal_cyc_spatial), seasonal_cyc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37bca5be-925f-4e9e-869a-fa1527cc0f83",
   "metadata": {},
   "source": [
    "## interpolation / resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f372ea3-cc52-4623-8f48-7a0ab1add942",
   "metadata": {},
   "source": [
    "### averaging in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f575d1f8-a292-4b97-be3d-7a8769cefdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Resample to quarterly (3-month) averages, where\n",
    "## the first quarter starts in December (\"QS-DEC\"),\n",
    "## and each point is labeled by the first month in the quarter\n",
    "anomalies_seasonal = anomalies.resample({\"time\": \"QS-DEC\"}).mean()\n",
    "\n",
    "## To extract the Dec-Jan-Feb season:\n",
    "fig, ax = plt.subplots(figsize=(4, 3))\n",
    "\n",
    "## plot data\n",
    "ax.step(anomalies_seasonal.time, anomalies_seasonal, where=\"post\", label=\"seasonal\")\n",
    "ax.plot(anomalies.time, anomalies, c=\"k\", alpha=0.3, label=\"monthly\")\n",
    "\n",
    "## label plot\n",
    "ax.set_ylabel(r\"$T$ anomaly ($K$)\")\n",
    "ax.set_yticks([-0.5, 0.0, 0.5])\n",
    "ax.set_xticks(ax.get_xticks()[::3])\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter(\"%Y\"))\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d51c957-8334-4bcb-8e4b-0d62f696a36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## annual mean, 2 different ways\n",
    "anomalies_annual0 = anomalies.resample({\"time\": \"YS-JAN\"}).mean()\n",
    "anomalies_annual1 = anomalies.groupby(\"time.year\").mean()\n",
    "print(np.allclose(anomalies_annual0, anomalies_annual1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b313eb-341e-4b17-a19c-929064522698",
   "metadata": {},
   "source": [
    "### Resampling in space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa822db2-a3c4-4bdc-907d-15b8e4695c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Downsample by averaging in space\n",
    "lat_coarse = T2m_trimmed.latitude[::4]\n",
    "lon_coarse = T2m_trimmed.longitude[::4]\n",
    "\n",
    "## Do the downsampling (linear interpolation is default)\n",
    "T2m_coarse = T2m_trimmed.interp({\"longitude\": lon_coarse, \"latitude\": lat_coarse})\n",
    "\n",
    "print(f\"Original shape:     {T2m_trimmed[\"t2m\"].shape}\")\n",
    "print(f\"After downsampling: {T2m_coarse[\"t2m\"].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cda6e1-f5ae-4a59-9250-04191d568e22",
   "metadata": {},
   "source": [
    "## Detrending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4bfa15-f805-4369-b9c2-3e77ffb88604",
   "metadata": {},
   "source": [
    "To illustrate detrending, let's load in a longer timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1b2159-2026-4b7b-8450-97c9e1325425",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define a preprocessing function\n",
    "def preprocess(data):\n",
    "    \"\"\"pre-process data before loading it:\n",
    "    1. Downsample in space\n",
    "    2. only get DJF months\n",
    "    \"\"\"\n",
    "    ## 1. Downsample in space\n",
    "    data_ = data.interp({\"longitude\": lon_coarse, \"latitude\": lat_coarse}).compute()\n",
    "\n",
    "    ## 2. Find indices of winter season\n",
    "    month = data_.time.dt.month\n",
    "    is_winter = (month == 12) | (month <= 2)\n",
    "\n",
    "    ## select winter season\n",
    "    data_ = data_.sel(time=is_winter)\n",
    "\n",
    "    return data_\n",
    "\n",
    "\n",
    "def djf_avg(data):\n",
    "    \"\"\"function to get Dec-Jan-Feb average\"\"\"\n",
    "\n",
    "    ## first, resample from monthly to seasonal\n",
    "    data_ = data.resample({\"time\": \"QS-DEC\"}).mean()\n",
    "\n",
    "    ## next, select DJF season\n",
    "    is_winter = data_.time.dt.month == 12\n",
    "    data_ = data_.sel(time=is_winter)\n",
    "\n",
    "    ## for convenience, replace \"time\" index with \"year\":\n",
    "    ## label with year for Jan, (so Dec-'78,Jan-'79,Feb-'79 -> 1979)\n",
    "    year = data_.time.dt.year.values + 1\n",
    "    data_[\"time\"] = year\n",
    "    data_ = data_.rename({\"time\": \"year\"})\n",
    "\n",
    "    return data_\n",
    "\n",
    "\n",
    "## load prepped data\n",
    "T2m_long = xr.open_mfdataset(file_list, preprocess=preprocess)\n",
    "\n",
    "## Get DJF average\n",
    "T2m_djf = djf_avg(T2m_long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf39e6-c4af-4acb-9dc0-c6becf67e433",
   "metadata": {},
   "source": [
    "Next, write a function to compute a trend along a given dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c3a19c-180d-4152-9572-21e0d20091b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trend(data, dim=\"year\"):\n",
    "    \"\"\"Get linear trend for an xr.dataarray along specified dimension\"\"\"\n",
    "\n",
    "    ## Get coefficients for best fit\n",
    "    polyfit_coefs = data.polyfit(dim=dim, deg=1)[\"polyfit_coefficients\"]\n",
    "\n",
    "    ## Get best fit line (linear trend in this case)\n",
    "    trend = xr.polyval(data[dim], polyfit_coefs)\n",
    "\n",
    "    return trend\n",
    "\n",
    "\n",
    "## compute the trend\n",
    "T2m_trend = get_trend(T2m_djf[\"t2m\"])\n",
    "\n",
    "## Get detrended version\n",
    "T2m_detrended = T2m_djf[\"t2m\"] - T2m_trend\n",
    "\n",
    "## compute spatial averages\n",
    "T2m_trend_avg = spatial_avg(T2m_trend)\n",
    "T2m_detrended_avg = spatial_avg(T2m_detrended)\n",
    "T2m_djf_avg = spatial_avg(T2m_djf[\"t2m\"])\n",
    "\n",
    "\n",
    "## plot result\n",
    "fig, ax = plt.subplots(figsize=(3, 2))\n",
    "ax.plot(T2m_djf_avg.year, T2m_djf_avg, label=\"DJF\")\n",
    "ax.plot(T2m_trend_avg.year, T2m_trend_avg, label=\"DJF trend\", c=\"k\", alpha=0.3)\n",
    "ax.plot(\n",
    "    T2m_detrended_avg.year,\n",
    "    T2m_detrended_avg + T2m_trend_avg.mean(),\n",
    "    label=\"DJF detrended\",\n",
    ")\n",
    "ax.set_yticks([285, 286])\n",
    "ax.set_xticks([1980, 2000, 2020])\n",
    "ax.legend(prop={\"size\": 8})\n",
    "ax.set_title(r\"North Atlantic $T_{2m}$\")\n",
    "ax.set_xlabel(\"Year\")\n",
    "ax.set_ylabel(r\"$T_{2m}$ ($K$)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c8672a-8e23-4ac6-9b00-3c9eaae0b862",
   "metadata": {},
   "source": [
    "## grid-wise and grid-to-point correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392a9afb-d99d-46d2-9b7c-ca48bf3368a9",
   "metadata": {},
   "source": [
    "Load in sea level pressure from ERA5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae05d665-16fd-4302-a685-bd42f3823f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get list of SLP files\n",
    "era5_path_slp = (\n",
    "    f\"{cmip6_fp}/era5/reanalysis/single-levels/monthly-means/mean_sea_level_pressure\"\n",
    ")\n",
    "slp_file_list = glob.glob(f\"{era5_path_slp}/*.nc\")\n",
    "\n",
    "## Open SLP over N. Atlantic\n",
    "slp = xr.open_mfdataset(slp_file_list, preprocess=preprocess)[\"msl\"]\n",
    "\n",
    "## convert from Pa to hPa (1 hPa = 100 Pa)\n",
    "slp *= 1 / 100\n",
    "\n",
    "## Get DJF average\n",
    "slp_djf = djf_avg(slp)\n",
    "\n",
    "## detrend\n",
    "slp_detrended = slp_djf - get_trend(slp_djf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c2e68d-9f05-4c8e-a31c-e609b0e88743",
   "metadata": {},
   "source": [
    "Get point-wise correlation between SLP and $T_{2m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb3067b-e982-4637-9404-c98f0ca14fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute correlation\n",
    "slp_T2m_corr = xr.corr(slp_detrended, T2m_detrended, dim=\"year\")\n",
    "\n",
    "\n",
    "def make_correlation_plot(correlation):\n",
    "\n",
    "    ## Plot results\n",
    "    fig = plt.figure(figsize=(6, 3))\n",
    "    ax = fig.add_subplot(projection=ccrs.PlateCarree())\n",
    "    ax, gl = plot_setup_north_atl(ax)\n",
    "\n",
    "    ## Plot data\n",
    "    corr_plot = ax.contourf(\n",
    "        correlation.longitude,\n",
    "        correlation.latitude,\n",
    "        correlation,\n",
    "        levels=src.utils.make_cb_range(1, 0.1),\n",
    "        cmap=\"cmo.balance\",\n",
    "        extend=\"both\",\n",
    "    )\n",
    "\n",
    "    ## add a colorbar and label\n",
    "    cb = fig.colorbar(corr_plot, orientation=\"vertical\", ticks=[-1, 0, 1])\n",
    "\n",
    "    return fig, ax\n",
    "\n",
    "\n",
    "fig, ax = make_correlation_plot(slp_T2m_corr)\n",
    "ax.set_title(r\"Correlation b/n $T_{2m}$ and SLP during winter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3002a22e-029d-4bfe-bbae-92f2c969771a",
   "metadata": {},
   "source": [
    "## Next, look at correlation between a single point the rest of the grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32449107-df25-4c8b-ba6f-a4217bef0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get SLP near Woods Hole\n",
    "T2m_woodshole = T2m_detrended.interp(latitude=41.5, longitude=288.5)\n",
    "\n",
    "## get correlation between Woods Hole T2m and North Atlantic SLP\n",
    "T2mWH_slp_corr = xr.corr(T2m_woodshole, slp_detrended, dim=\"year\")\n",
    "\n",
    "fig, ax = make_correlation_plot(T2mWH_slp_corr)\n",
    "ax.scatter(288.5, 41.5, marker=\"*\", c=\"k\", s=100)\n",
    "ax.set_title(r\"Correlation b/n Woods Hole SLP and $T_{2m}$ during winter\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c3929d-2f31-40a9-a0da-68849dc680ac",
   "metadata": {},
   "source": [
    "## Regridding data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d60caf-b46a-4afd-9254-209398f7b9e4",
   "metadata": {},
   "source": [
    "Next, we're going to load data on a non-regular grid (tripolar, in this case). Specifically, we'll look at sea surface temperature (SST) from the MIROC6 model's historical simulation. We'll show how to plot the data on it's native grid and how to regrid it to a regular lon/lat grid."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8797d82-01a9-4a0c-a526-e3e9001892d2",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a763ee-5ce6-4276-83fc-a3905098cea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "miroc6_fp = f\"{cmip6_fp}/cmip6/CMIP/MIROC/MIROC6/historical/r1i1p1f1/Omon/tos/gn/1\"\n",
    "fname = \"tos_Omon_MIROC6_historical_r1i1p1f1_gn_195001-201412.nc\"\n",
    "sst_miroc6 = xr.open_dataset(f\"{miroc6_fp}/{fname}\")\n",
    "sst_miroc6 = sst_miroc6.isel(time=slice(-36, None)).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9cc258-1157-4d56-ae17-840fb0519b27",
   "metadata": {},
   "source": [
    "#### Regridding to regular lon/lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2767c06b-4d2b-42a7-b049-29b5aba7bac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## should we use custom grid?\n",
    "use_custom_grid = True\n",
    "\n",
    "if use_custom_grid:\n",
    "    # create regular lon/lat grid\n",
    "    grid = xr.DataArray(\n",
    "        data=None,\n",
    "        coords={\"longitude\": np.arange(0, 360), \"latitude\": np.arange(-90, 91)},\n",
    "        dims=[\"longitude\", \"latitude\"],\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # use ERA5 grid\n",
    "    grid = T2m_detrended.isel(year=0)\n",
    "\n",
    "## do the regridding\n",
    "regridder = xe.Regridder(ds_in=sst_miroc6, ds_out=grid, method=\"bilinear\")\n",
    "sst_miroc6_regridded = regridder(sst_miroc6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f47992-aee5-453e-8f2f-d226debdf2fa",
   "metadata": {},
   "source": [
    "#### Plot data on native and regular grids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e58094-1c06-461b-af7b-fad1b972f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up the plot\n",
    "fig = plt.figure(figsize=(10, 2.5))\n",
    "\n",
    "## canvas for plot on native grid\n",
    "ax = fig.add_subplot(1, 2, 1, projection=ccrs.PlateCarree())\n",
    "ax, gl = plot_setup_north_atl(ax)\n",
    "\n",
    "## canvas for plot with regridded data\n",
    "ax_regridded = fig.add_subplot(1, 2, 2, projection=ccrs.PlateCarree())\n",
    "ax_regridded, gl_regridded = plot_setup_north_atl(ax_regridded)\n",
    "\n",
    "## Plot data on native grid\n",
    "ax.set_title(\"Native grid\")\n",
    "sst_plot = ax.pcolormesh(\n",
    "    sst_miroc6.longitude,\n",
    "    sst_miroc6.latitude,\n",
    "    sst_miroc6[\"tos\"].mean(\"time\"),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    vmin=-2,\n",
    "    vmax=32,\n",
    ")\n",
    "cb = fig.colorbar(sst_plot)\n",
    "\n",
    "## Plot regridded data\n",
    "ax_regridded.set_title(\"Regridded\")\n",
    "xx, yy = np.meshgrid(sst_miroc6_regridded.longitude, sst_miroc6_regridded.latitude)\n",
    "sst_plot_regridded = ax_regridded.pcolormesh(\n",
    "    xx,\n",
    "    yy,\n",
    "    sst_miroc6_regridded[\"tos\"].mean(\"time\"),\n",
    "    cmap=\"cmo.thermal\",\n",
    "    vmin=-2,\n",
    "    vmax=32,\n",
    ")\n",
    "cb = fig.colorbar(sst_plot_regridded, ticks=[0, 10, 20, 30])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
